# -*- coding: utf-8 -*-
"""segmentation_with_EndPoints&lines.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gSJdfDAb8o6fsM-bx9RpBP_7K-8BBz3C
"""

from google.colab import drive
drive.mount('/content/drive')

from keras.layers import Input, Conv2D, MaxPooling2D
from keras.layers import Dense, Flatten
from keras.models import Model

_input = Input((224,224,1)) 

conv1  = Conv2D(filters=64, kernel_size=(3,3), padding="same", activation="relu")(_input)
conv2  = Conv2D(filters=64, kernel_size=(3,3), padding="same", activation="relu")(conv1)
pool1  = MaxPooling2D((2, 2))(conv2)

conv3  = Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu")(pool1)
conv4  = Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu")(conv3)
pool2  = MaxPooling2D((2, 2))(conv4)

conv5  = Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu")(pool2)
conv6  = Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu")(conv5)
conv7  = Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu")(conv6)
pool3  = MaxPooling2D((2, 2))(conv7)

conv8  = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(pool3)
conv9  = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(conv8)
conv10 = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(conv9)
pool4  = MaxPooling2D((2, 2))(conv10)

conv11 = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(pool4)
conv12 = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(conv11)
conv13 = Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(conv12)
pool5  = MaxPooling2D((2, 2))(conv13)

flat   = Flatten()(pool5)
dense1 = Dense(4096, activation="relu")(flat)
dense2 = Dense(4096, activation="relu")(dense1)
output = Dense(1000, activation="softmax")(dense2)

vgg16_model  = Model(inputs=_input, outputs=output)

from keras.applications.vgg16 import decode_predictions
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
import matplotlib.pyplot as plt 
from PIL import Image 
import seaborn as sns
import pandas as pd 
import numpy as np 
import os 

def _load_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)
    return img 

def _get_predictions(_model):
    f, ax = plt.subplots(1, 4)
    f.set_size_inches(80, 40)
    for i in range(4):
        ax[i].imshow(Image.open(imgs[i]).resize((200, 200), Image.ANTIALIAS))
    plt.show()
    
    f, axes = plt.subplots(1, 4)
    f.set_size_inches(80, 20)
    for i,img_path in enumerate(imgs):
        img = _load_image(img_path)
        preds  = decode_predictions(_model.predict(img), top=3)[0]
        b = sns.barplot(y=[c[1] for c in preds], x=[c[2] for c in preds], color="gray", ax=axes[i])
        b.tick_params(labelsize=55)
        f.tight_layout()

from keras.applications.resnet50 import ResNet50
resnet50 = ResNet50(weights='imagenet', include_top=False)

def _get_features(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_data = image.img_to_array(img)
    img_data = np.expand_dims(img_data, axis=0)
    img_data = preprocess_input(img_data)
    resnet_features = resnet50.predict(img_data)
    return resnet_features

basepath = "/content/drive/My Drive/IP/Dataset/Training set/"
class1 = os.listdir(basepath + "Or/")
class2 = os.listdir(basepath + "And/")

data = {'Or': class1[::], 
        'And': class2[::], 
        'test': [class1[111], class2[111]]}

features = {"Or" : [], "And" : [], "test" : []}
testimgs = []

for label, val in data.items():
    for k, each in enumerate(val):        
        if label == "test" and k == 0:
            img_path = basepath + "/Or/" + each
            testimgs.append(img_path)
        elif label == "test" and k == 1:
            img_path = basepath + "/And/" + each
            testimgs.append(img_path)
        else: 
            img_path = basepath + label.title() + "/" + each
        feats = _get_features(img_path)
        features[label].append(feats.flatten())

dataset = pd.DataFrame()
for label, feats in features.items():
    temp_df = pd.DataFrame(feats)
    temp_df['label'] = label
    dataset = dataset.append(temp_df, ignore_index=True)

import pickle

y = dataset[dataset.label != 'test'].label
X = dataset[dataset.label != 'test'].drop('label', axis=1)

#  for saving data
pickle_out = open("X.pickle", "wb")
pickle.dump(X, pickle_out)
pickle_out.close()

pickle_out = open("y.pickle", "wb")
pickle.dump(y, pickle_out)
pickle_out.close()

from sklearn.feature_selection import VarianceThreshold
from sklearn.neural_network import MLPClassifier
from sklearn.pipeline import Pipeline

model = MLPClassifier(hidden_layer_sizes=(100, 10))
pipeline = Pipeline([('low_variance_filter', VarianceThreshold()), ('model', model)])
pipeline.fit(X, y)

print ("Model Trained on pre-trained features")

preds = pipeline.predict(features['test'])

f, ax = plt.subplots(1, 2)
for i in range(2):
    ax[i].imshow(Image.open(testimgs[i]).resize((200, 200), Image.ANTIALIAS))
    ax[i].text(10, 180, 'Predicted: %s' % preds[i], color='k', backgroundcolor='red', alpha=0.8)
plt.show()

"""# **SEGMENTATION PART**"""

# Read Image
import cv2
import imutils
import cv2

img = cv2.imread("/content/drive/My Drive/IP/Colab/Version_1/comp_1.jpeg")
empty     = (np.copy(img)) * 0 
white   = (np.copy(img)) * 0 + 255
original  = (np.copy(img))
lines_img = (np.copy(img))

And = []
Or  = []

# Convert to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Binarization (thresholding)
ret, thresh_1 = cv2.threshold(gray, 80, 255, cv2.THRESH_BINARY)

# Denoizing (Removing noise)
kernel = np.ones((5, 5), np.uint8)
erosion = cv2.erode(thresh_1, kernel, iterations = 1)
# cv.imshow("", erosion)


# ------SEGMENTATION------

# 1. canny edge detection
edged = cv2.Canny(erosion, 30, 200)
# 2. Finding contours
contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

num_rect = 1

# print the area of each contour
i = 1
total_area = 0

for cnt in contours:
  area = cv2.contourArea(cnt)
  total_area = total_area + area
  print("Area " + str(i) + "-->" + str(area))
  i = i + 1
  
mean_area = total_area / len(contours)
  
for c in contours:
  # for all the contours do the following
  # if area of the contour is smaller than mean area don't do anything
  if cv2.contourArea(c) <= mean_area - mean_area / 2:
      continue  
  
  # if area of the contour is larger than mean area find the best rectangle bounding this contour, and find it's coordinates   
  x,y,w,h = cv2.boundingRect(c)
  #rect = cv2.rectangle(img, (x - 12, y - 12), (x + w + 12, y + h + 12), (0, 255,0), 4) # 4 is the line's thickness
  new_img_2 = img.copy() # make a copy of the original image to work on it

  fig = plt.figure() # a new figure for every (plt) plot, (necessary nefore each plt.imshow(img) to be able to show many images)
  
  empty[y - 20 : y + h + 20, x - 20 : x + w + 20]     = original[y - 20 : y + h + 20, x - 20 : x + w + 20]
  lines_img[y - 20 : y + h + 20, x - 20 : x + w + 20] = white[y - 20 : y + h + 20, x - 20 : x + w + 20]
  
  new_img_2 = new_img_2[y - 20 : y + h + 20, x - 20 : x + w + 20]  # crop the image in the place of the rectabgle contour

  ####################################
  # prediction part 
  new_img_2 = cv2.resize(new_img_2, (224, 224), interpolation = cv2.INTER_AREA) 
  img_data = image.img_to_array(new_img_2)
  img_data = np.expand_dims(img_data, axis=0)
  img_data = preprocess_input(img_data)
  resnet_features = resnet50.predict(img_data)
  go = []
  go.append(resnet_features.flatten())
  preds = pipeline.predict(go)

  if preds[0] == 'And':
    And.append([x,y,w,h])
  else:
    Or.append([x,y,w,h])
  
  # get end points

  extLeft  = tuple(c[c[:, :, 0].argmin()][0])
  extRight = tuple(c[c[:, :, 0].argmax()][0])
  extTop   = tuple(c[c[:, :, 1].argmin()][0])
  extBot   = tuple(c[c[:, :, 1].argmax()][0])

  # draw the outline of the object, then draw each of the
  # extreme points, where the left-most is red, right-most
  # is green, top-most is blue, and bottom-most is teal
  cv2.drawContours(original, [c], -1, (0, 255, 255), 2)
  cv2.circle(original, extLeft, 8, (0, 0, 255), -1)
  cv2.circle(original, extRight, 8, (0, 255, 0), -1)
  cv2.circle(original, extTop, 8, (255, 0, 0), -1)
  cv2.circle(original, extBot, 8, (255, 255, 0), -1)

  #end of get points
  
  plt.imshow(new_img_2)
  plt.text(10, 180, 'Predicted: %s' % preds[0], color='k', backgroundcolor='red', alpha=0.8)
  plt.show()
  #
  #####################################
  center = (x,y)
  print ("center -- >", center)
  num_rect = num_rect + 1




print("Number of rectangles = " + str(num_rect))
print("Mean area = ", mean_area)
#print(contours)
print('Numbers of contours found=' + str(len(contours)))


# use -1 as the 3rd parameter to draw all the contours
#cv2.drawContours(img, contours, -1, (0, 255, 0), 3)
fig = plt.figure()
plt.imshow(original)
plt.show()
plt.imshow(empty)
plt.show()
plt.imshow(original - empty)
plt.show()

plt.imshow(lines_img)
plt.show()

LineImage = (np.copy(img-empty))

print("And\n")
print(And)

print("ــــــــــــــــــــــــــــــــــــــــــــــــ")

print("Or\n")
print(Or)

import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np 
import random
import math


def getLines(lines_img):
  edges = cv2.Canny(lines_img,50,150,apertureSize = 3)

  rho = 1  # distance resolution in pixels of the Hough grid
  theta = np.pi / 180  # angular resolution in radians of the Hough grid
  threshold = 30 # minimum number of votes (intersections in Hough grid cell)
  min_line_length = 10  # minimum number of pixels making up a line
  max_line_gap = 10  # maximum gap in pixels between connectable line segments

  # Run Hough on edge detected image
  # Output "lines" is an array containing endpoints of detected line segments
  lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),
                      min_line_length, max_line_gap)
  go = []
  for line in lines:
    for i in line :
      x1, y1, x2, y2 = i
      go.append([x1, y1, x2, y2])
  return go

#############

def takeSecond(elem):
    return elem[1]

#############
X1 = []
X2 = []
Y1 = []
Y2 = []
Color=[]
count=0

lines = getLines(lines_img)
Black = (np.copy(lines_img)) * 0  # creating a blank to draw lines on


count=0
# sort list with key

lines.sort(key=takeSecond)


for line in lines:
    x1=line[0]
    y1=line[1]
    x2=line[2]
    y2=line[3]
    cv2.line(Black, (x1, y1), (x2, y1),[255,255,255], 5)


kernel = np.ones((6, 6), np.uint8)
erosion = cv2.erode(Black, kernel, iterations = 1)
img_dilation = cv2.dilate(erosion, kernel, iterations=1) 

plt.imshow(Black) 
plt.show() 

lines = getLines(img_dilation)
Black = (np.copy(lines_img)) * 0  # creating a blank to draw lines on

plt.imshow(Black) 

lines.sort(key=takeSecond)
for line in lines:
    x1=line[0]
    y1=line[1]
    x2=line[2]
    y2=line[3]

    if count > 0:
      if (y1 - p_y1) > 0 and (y1 - p_y1) < 15  and (y2 - p_y2) > 0 and (y2 - p_y2) < 15: 
        p_x1=line[0]
        p_y1=line[1]
        p_x2=line[2]
        p_y2=line[3]
        continue
      elif (p_y1 - y1) > 0 and (p_y1 - y1) < 15 and (p_y2 - y2) > 0 and (p_y2 - y2) < 15:
        p_x1=line[0]
        p_y1=line[1]
        p_x2=line[2]
        p_y2=line[3]
        continue
    cv2.line(Black, (x1, y1), (x2, y1),[255,255,255], 5)
    count = count +1 
    p_x1=line[0]
    p_y1=line[1]
    p_x2=line[2]
    p_y2=line[3]

plt.imshow(Black) 
plt.show() 
print(count)

